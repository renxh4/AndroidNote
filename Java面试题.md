# Java 集合

## 集合概念

### 1.数组的弊端：
* 长度是固定的，后期不能改变；
* 数组一旦定以后，其类型就固定了，只能存储此类型数据；

### 2.集合的好处：

* Java为我们提供了一些类，这些叫：集合类。这些集合类功能类似于"数组"，
    为程序员做"容器"用的

* 我们程序员使用集合时，可以不用关心"长度"信息，我们只需要往里面存东西，或者从内部删除元素,集合类会自动扩容

## 体系结构

### 一 .Collection(接口):单列集合

#### List(接口):1.有序；2.可以存储重复值
* ArrayList(类):数组实现；
    * 线程不安全(不同步)，效率高；
* Vector(类):数组实现；
    * 线程安全的(同步)，效率低；
* LinkedList(类):链表；
    * 线程不安全的(不同步)，效率高；

#### Set(接口):1.无序的；2.不能存储重复值
* HashSet(类):哈希表；
    * 保证元素唯一性：hashCode()和equals()
* LinkedHashSet(类):链表、哈希表；(特例：有序的)
	* 由链表保证顺序；
	* 由哈希表保证唯一性；
* TreeSet(类):树；
	* 对元素排序和保证元素唯一性：
		* 1.自然排序：
		    * 1).自定义类，实现：Comparable接口；
		    * 2).重写compareTo()方法；
		* 2.比较器排序：
		    * 1).自定义比较器，实现：Comparetor接口；
		    * 2).重写compare()方法；
		    * 3).实例化TreeSet时，将自定义比较器作为参数传递给TreeSet的构造方法；

## 二.Map(接口):双列集合
* HashMap(类):键：哈希表结构
* LinkedHashMap(类):键：链表、哈希表结构；
* TreeMap(类):键：树；
* Hashtable(类):键：哈希表结构

## 一些常见集合问题

### HashMap和Hashtable的区别：
* HashMap可以存储null键和null值；
* Hashtable不能存储null键和null值；
* HashMap线程不安全的(不同步)；
* Hashtabel线程安全的；
* StringBuilder是非线程安全的，StringBuffer是线程安的。

### 数据结构：
* 数组：查询快O（1）；增删慢O（n）；
* 链表：查询慢O（n）；增删快O（1）；
* 哈希表：综合了数组和链表的优点，查询、增、删都很快O（1）；关键取决于哈希算法；
* 栈：先进后出；
* 队列：先进先出；
* 树：小的存到左边，大的存到右边，相同的不存；平衡二叉查找树查询、增、删O（logn）
### 遍历的方式：
#### Collection
* 1).toArray();
* 2).iterator();
* 3).增强for();
#### Map
* 1).keySet():键集合；
* 2).entrySet():键值对的集合；

## 集合源码解析

### ArrayList
* 有序，可重复
* 底层实现是数组
* 查询快增删慢
* 线程不安全
* ArrayList 的初始大小是0，然后，当add第一个元素的时候大小则变成10。并且，在后续扩容的时候会变成当前容量的1.5倍大小。

### Vector
* 和上面的区别就是，线程安全
* 扩容为原来的一倍
### LinkedList
* 有序，可重复
* 底层使用双向链表
* 线程不安全
* 查询慢，增删块

### HashSet
* 底层实现哈希表，内部HashMap实现
* 排列无需，不可重复
* 存储查询速度快
* 保证元素唯一性：元素的hashCode()和equals()
```java
/*
 * 当使用HashSet存储自定义对象时，我们要重写hashCode()和equals()方法；
 * 
 * 因为：HashSet内部的add()方法，先判断hashCode()是否相同，如果相同，再判断equals()，如果equals()也相同：不存；
 * 
 * 源码：if(e.hash == hash && ((k = e.key) == key || key.equals(k))){
 * 	   }
 *    
 */
```
### LinkedHashSet
* 链表、哈希表；(特例：有序的)
* 由链表保证顺序；
* 由哈希表保证唯一性；
* 内部实现LinkedHashMap

### TreeSet
* 底层由二叉树（红黑树）结构实现
* 无序不可重复
* 小的存左边，大的存右边
* 底层使用TreeMap实现

#### 当使用TreeSet存储自定义对象时：
 * 1.实现"自然排序"：
    * 1.要存储的元素实现Comparable接口；
    * 2.并重写compareTo()方法；
 * 或者
 * 2.实现"比较器"：
    * 	1.要存储的元素，无需实现任何接口；
    * 	2.自定义比较器类，实现：Comparator接口；重写：compare()方法；
    * 	3.在实例化TreeSet时，将自定义的比较器传给TreeSet构造方法；

### HashMap

#### 散列函数
顾名思义他是一个函数，假如我们把它记做`hash(key)`，其中key表示元素的键值，`hash(key)`表示经过散列函数计算得到的散列值，把它作为数组的下标，这个函数有三个要求
* 散列函数计算得到的散列值是一个非负整数；（由于数组下标是从0开始的，所以不能为非负数）
* 如果 key1 = key2，那 hash(key1) == hash(key2)；
* 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。（看起来合情合理，但是想要找到一个key值不同，hash值也不同的函数几乎不可能，这个就是散列冲突）

设计散列函数需要注意的点
* 散列函数不能太复杂，太复杂会消耗时间，造成性能的下降
* 散列函数生成的值需要尽可能的均匀分布，减少散列冲突的发生

#### 散列冲突
散列冲突有俩种解决方法
* 开放寻址法

    开放寻址法的核心思想，如果出现了散列冲突，我们就需要重新探测一个空闲位置，将其插入

    **优点**

    散列表数据都存在数组中，不需要额外拉链表，可以有效利用cpu缓存加快查询

    **缺点**

    删除数据比较麻烦，需要特殊标记已经删除的数据，而且所有数据都存在数组中，散列冲突的概率会变得更大，所以装载因子上限不能太大，这也导致更加浪费空间

    **总结**

    当数据量较小，装载因子小的时候适合使用开放寻址法

* 链表法

    链表法是一种更加常用的方式，核心思想是，在链表的每个桶或者槽中（就是数组的每个元素位置），都对应一个链表，把hash值相同的放入链表中

    * 相比开放寻址更加节省空间，因为链表的节点只有需要的时候才申请空间，而不是需要提前申请
    * 链表法相比开放寻址法，对大装载因子的容忍率更高，即使装载因子变成了10，也就是链表长一点
    * 链表需要储存指针，会消耗内存，但是如果储存的是大对象，那么这点指针的内存消耗可易忽略不计
    * 链表法更加灵活，我们可以把链表换为更加高效的数据结构，比如：红黑树，即使散列表退化到最差的情况，查询效率也是O（logn）

    **总结**
    
    链表法比较适合存储大对象，大量数据的散列表，而且更加灵活，有很多的优化策略

#### 装载因子

这个表示数组中空位的多少，其计算公式为

`散列表的装载因子=填入表中的元素个数/散列表的长度`

装载因子越大，说明空闲位置越少，散列冲突越多，散列表的性能就会下降

**装载因子过大怎么办？**
当装载因子过大，就需要动态扩容，重新申请一个更大的散列表

**如何避免低效扩容**
如果数据量很大，那么搬运数据就会很麻烦，这种情况下我们可以采取，把搬运工作穿插在插入期间，集体就是，每次插入数据，我们就把旧散列表的一部分数据，搬运到新散列表，直到搬运完所有


#### HashMap的源码分析

* 初始大小

    HashMap的初始大小是16，这个是可以设置的，如果事先知道数据的大小，可以直接设置大小，减少动态扩容的时间，增加效率

    capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。

* 装载因子和动态扩容

    默认的装载因子是0.75，当HashMap的元素个数超过0.75*capacity（capacity 表示散列表的容量）时，就会启动动态扩容，每次扩容都是上一次的俩倍

* 散列冲突的解决方法

    HashMap 底层采用链表法来解决冲突，即使散列函数和转载因子设计的在合理，也免不了链表过长的情况，一旦链表过长就会严重影响HashMap的执行效率

    于是在Jdk1.8做了优化，当链表长度大于8时，就会转化为红黑树，当链表长度小于8时，就会转为链表，因为在数据量较小的情况下，红黑树要维持平衡，比起链表优势并不是很明显

* 散列函数
    
    HashMap散列函数设计的并不复杂，简单高效，分布均匀，代码如下：

    ```java
    int hash(Object key) {
         int h = key.hashCode()； 
         return (h ^ (h >>> 16)) & (capicity -1); //capicity表示散列表的大小
         }
    ```

    [为什么要先高16位异或低16位再取模运算](https://www.cnblogs.com/Profound/p/10879101.html)

    极客时间数据结构算法之美的第19章也有相应的解释

### HashTable
* HashMap可以存储null键和null值；
* Hashtable不能存储null键和null值；
* HashMap线程不安全的(不同步)；
* Hashtabel线程安全的；
* 效率较低
### LinkedHashMap
* HashMap的一个子类
* 底层散列表和双向链表实现
* 散列表存储数据，双向链表保证顺序
* 这个就是一个天然的Lru算法，可以按照访问顺序储存，访问已有数据，会从原来位置移除，添加到链表尾部，插入数据，如果链表满了，则会删除链表头部数据

### TreeMap
* 底层树结构储存
* 有顺序的储存
* key 必须实现 Comparable 接口或者在构造 TreeMap 传入自定义的Comparator

###  ConcurrentHashMap

* 由于HashTable线程安全，但是效率太低，所以ConcurrentHashMap来解决这个问题
* 线程安全的，效率高
* Jdk1.7之前，采用多个`segment`组成,每个`segment`继承`ReentrantLock`,这其实就是分桶操作，把所有数据分成n个桶分别储存，每个桶都有单独的锁，这样理论是桑拿来讲，可以同时又n个线程并发操作ConcurrentHashMap，这样就大大提高了效率
* Jdk1.8之后，采用了CAS + synchronized来保证并发安全
* CAS：乐观锁的一种技术，当多个线程更新一个共享变量的数据，只有一个线程可以更新成功，其他线程都会失败，但不会被挂起，而是被告知竞争失败，可以再次进行尝试，主要包括以下三个操作
    * 需要读写内存的位置V
    * 进行比较的预期原值A
    * 拟写入的新值B
    * 三个参数，一个当前内存值 V、旧的预期值 A、即将更新的值 B，当且仅当预期值 A 和内存值 V 相同时，将内存值修改为 B 并返回 true，否则什么都不做，并返回 false。

* 如果CAS不成功，会一直自旋，直到成功，如果长时间不成功，会给cpu带来很大的开销
* ABA问题，比如说一个线程T1从内存位置V中取出A，这时候另一个线程T2也从内存中取出A，并且T2进行了一些操作变成了B，然后T2又将V位置的数据变成A，这时候线程T1进行CAS操作发现内存中仍然是A，然后T1操作成功。尽管线程T1的CAS操作成功，但可能存在潜藏的问题。JDK 1.5 以后的 AtomicStampedReference 类一定程度上解决了这个问题

### Hashmap底层为什么是线程不安全的？

* 并发场景下使用时容易出现死循环，在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环；

* 在 1.7 中 hash 冲突采用的头插法形成的链表，在并发条件下会形成循环链表，一旦有查询落到了这个链表上，当获取不到值时就会死循环。


# Java 反射

## class对象的作用

假定我们在编译期已知道了所有类型(在没有反射机制创建和使用类对象时，一般都是编译期已确定其类型，如new对象时该类必须已定义好)，另外一种是反射机制，它允许我们在运行时发现和使用类型的信息。在Java中来表示运行时类型信息的就是class类，Class类是一个实实在在的类，存在于JDK的java.lang包下

Class类创建对象后就是Class对象，Class对象表示的是自己手动编写的类型信息，比如创建一个Shape类，那么JVM会创建一个shape对象的Class类的Class对象，该Class保存了shape对象的类型信息，实际上每个java类都有一个Class对象，每当我们编写并编译一个新的类就会产生一个对应的Class对象，并且这个Class对象会被保存在同名的.class文件中，编译后的字节码文件保存的就是Class对象，那么为什么需要一个class对象？当我们new一个对象或者引用一个静态成员变量时，JVM中的类加载器会将对应的class文件加载到JVM中，然后JVM根据这个类型信息创建我们需要的实例对象，或者提供静态变量的引用值，注意，不管创建多少个对象，JVM中只存在一个Class对象

* 1 Class类也是类的一种，与class关键字不一样
* 2 手动编写的类编译后会产生一个Class对象，其表示的是类的类型信息，而这个Class对象会保存在同名的.class字节码文件中
* 3 通过关键字class，定义的类在内存中有且只有一个Class对象来描述其类型信息
* 4 Class类只有私有的构造方法，只能由JVM来创建和加载
* 5 Class类对象的作用是运行时获取类的类型信息，这个对反射技术很重要

# Java 泛型

## 类型擦除

java的泛型是伪泛型，这是因为在java的编译期间，所有的泛型信息都会被擦除掉，在生成的字节码中不存在泛型的信息，在使用泛型的时候加上的类型参数，在编译器编译的时候会被去掉，这个过程叫做泛型擦除

## 类型擦除后保留的原始类型
什么叫原始类型？

原始类型就是擦除泛型信息后，最后在字节码变量的真正类型，无限定类型用`Object`替换,有限定类型使用其限定类型

`Pair<T>` 这个就是无限定类型，其中`T`被`Object`代替

`Pair<T extends Comparable>` 这个就是有限定类型，其中的`T`被`Comparable`替代

## 泛型擦除会引起的问题

* 1 类型擦除与多态的冲突

    [解决方法](https://cloud.tencent.com/developer/article/1582529)

* 2 泛型类型变量不能是基本数据类型
* 3 泛型在静态方法和静态类中的问题
    ```java
    public class Test2<T> {    
    public static T one;   //编译错误    
    public static  T show(T one){ //编译错误    
        return null;    
    }    
    }
    ```
    因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。

# Java 注解

注解相当于一种标记，在程序中加了注解就等于为程序打上了某种标记。程序可以利用ava的反射机制来了解你的类及各种元素上有无何种标记，针对不同的标记，就去做相应的事件。标记可以加在包，类，字段，方法，方法的参数以及局部变量上。

## 元注解
元注解是可以注解到注解上的注解，元注解是一种基本注解，他可以应用到其他注解上

* @Retention
    * RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视。
    * RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中。
    * RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。
* @Target
    * ElementType.ANNOTATION_TYPE 可以给一个注解进行注解
    * ElementType.CONSTRUCTOR 可以给构造方法进行注解
    * ElementType.FIELD 可以给属性进行注解
    * ElementType.LOCAL_VARIABLE 可以给局部变量进行注解
    * ElementType.METHOD 可以给方法进行注解
    * ElementType.PACKAGE 可以给一个包进行注解
    * ElementType.PARAMETER 可以给一个方法内的参数进行注解
    * ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举
## 注解使用
注解如果不提取，跟注释没有太大区别，没有太大的作用，怎么才能让注解工作起来呢？这就离不开反射，我们使用反射提取在方法或者类上的注解，去做一些事情

* 1 提供信息给编译器：编译器可以利用注解来探测错误和警告信息
* 2 编译阶段时的处理：软件工具可以用注解信息生成代码，HTML文档，或者其他相应的处理
* 3 运行时的处理：某些注解可以运行时接受代码提取

# Java 内部类

## 为什么局部内部类和匿名内部类只能访问局部final变量？

```java
public class Test {
    public static void main(String[] args)  {
         
    }
     
    public void test(final int b) {
        final int a = 10;
        new Thread(){
            public void run() {
                System.out.println(a);
                System.out.println(b);
            };
        }.start();
    }
}
```
　　上段代码中，如果把变量a和b前面的任一个final去掉，这段代码都编译不过。我们先考虑这样一个问题：

当test方法执行完毕之后，变量a的生命周期就结束了，而此时Thread对象的生命周期很可能还没有结束，那么在Thread的run方法中继续访问变量a就变成不可能了，但是又要实现这样的效果，怎么办呢？Java采用了 复制  的手段来解决这个问题。

如果局部变量的值在编译期间就可以确定，则直接在匿名内部里面创建一个拷贝。如果局部变量的值无法在编译期间确定，则通过构造器传参的方式来对拷贝进行初始化赋值。

从上面可以看出，在run方法中访问的变量a根本就不是test方法中的局部变量a。这样一来就解决了前面所说的 生命周期不一致的问题。但是新的问题又来了，既然在run方法中访问的变量a和test方法中的变量a不是同一个变量，当在run方法中改变变量a的值的话，会出现什么情况？

对，会造成数据不一致性，这样就达不到原本的意图和要求。为了解决这个问题，java编译器就限定必须将变量a限制为final变量，不允许对变量a进行更改（对于引用类型的变量，是不允许指向新的对象），这样数据不一致性的问题就得以解决了。

# Java并发

在 Java 中，一个应用程序对应着一个JVM实例（JVM进程）。Java采用的是 单线程编程模型 ，即在我们自己的程序中如果没有主动创建线程的话，只会创建一个线程，通常称为主线程。但是要注意，虽然只有一个线程来执行任务，不代表JVM中只有一个线程，JVM实例在创建的时候，同时会创建很多其他的线程（比如垃圾收集器线程）。由于Java采用的是单线程编程模型，因此在进行UI编程时要注意将耗时的操作放在子线程中进行，以避免阻塞主线程（在UI编程时，主线程即UI线程，用来处理用户的交互事件）。

## 线程的几种状态
* 1、新建状态（New）：新创建了一个线程对象。
* 2、就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。
* 3、运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。
* 4、阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：
    * （一）、等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)
    * （二）、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
    * （三）、其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁）
* 5、死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

## 线程控制之线程中断
中断线程
* 1 public final void stop(); 不建议使用

* 2 public void interrupt(); 前提条件： 线程内部一定要处于以下三种阻塞
    * （1） Object—wait
    * （2）Thread --sleep
    * （3）Thread–yield

## Synchronized

`互斥锁`，即 能到达到互斥访问目的的锁。举个简单的例子，如果对临界资源加上互斥锁，当一个线程在访问该临界资源时，其他线程便只能等待。

在 Java 中，可以使用 synchronized 关键字来标记一个方法或者代码块，当某个线程调用该对象的synchronized方法或者访问synchronized代码块时，这个线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，这个线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。

### synchronized方法需要注意以下问题

* `当一个线程正在访问一个对象的synchronized方法时，那么其他线程不能访问该对象的其他synchronized方法`，因为一个对象只有一把锁，当一个线程获取对象锁之后，其他线程无法获取对象锁，所以其他线程无法访问对象的其他synchronized方法

* `当一个线程正在访问一个对象的synchronized方法，那么其他线程可以访问这个对象的其他非synchronized方法。`这是因为非synchronized方法本身就不需要获得对象锁，假如一个方法没有设置synchronized，、说明不会使用临界资源（共享，可变资源），那么其他线程是可以访问这个方法的

* 如果线程A需要访问对象Student A 的fun方法,同时线程B需要访问Student B 的fun方法，（A B是同一类型），这是也可以正常访问，因为他们不是同一个对象，所以不会有并发问题

### synchronized代码块

下面就是一个synchronized代码块
```java
synchronized (lock){
    //访问共享可变资源
    ...
}
```
当某个线程执行这块代码时，该线程会获取对象lock的锁，其中lock可以是this（代表当前对象的锁），也可以是类中的某个属性（代表获取该属性的锁）

需要注意的是

对象的`同步方法`和`synchronized(this)`同步代码块是互斥的，因为他们锁的是同一个对象，但是与`synchronized(非this)`同步块是异步的，因为他们所的不是同一个对象

优点

synchronized代码块比synchronized方法粒度会更小一些，更加灵活，增加效率，只需要对需要同步的地方加锁

### class对象锁

每个类也会有一个锁，静态的synchronized方法就是以class对象作为锁，另外他可以控制staic的数据成员（由于static数据成员不属于任何对象，是类成员）的并发访问。

如果一个线程对一个对象的非static synchronized方法，另外一个线程需要执行此对象的static synchronized方法，也不会发成互斥现象，因为访问非static synchronized方法占用的是对象锁，访问static synchronized 占用的类锁，所以不存在互斥现象

synchronized 代码块实际上多了 monitorenter 和 monitorexit 两条指令， monitorenter指令执行时会让对象的锁计数加1，而monitorexit指令执行时会让对象的锁计数减1，对于synchronized方法，执行中的线程识别该方法的 method_info 结构是否有 ACC_SYNCHRONIZED 标记设置，然后它自动获取对象的锁，调用方法，最后释放锁。如果有异常发生，线程自动释放锁。

对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会导致死锁

### 可重入性

一版情况下，当每个线程请求一个其他线程持有的锁的时候会发生阻塞，然而java的内置锁是可重入的，因此当一个试图获取自己持有的锁的时候，这个请求就会成功，可重入锁最大的作用就是避免死锁

###  总结

synchronized 内置锁是一种对象锁（锁的是对象而非引用）作用的粒度是对象，可以用来实现临界资源的同步互斥访问，是可重入的

synchronized 包含俩个特征
* 互斥性：保证同一个时刻，只有一个线程可以执行某个方法或某个代码块
* 可见性：保证线程工作内存中变量和公共内存中的变量同步，使多线程读取变量时可以获得最新值

[Java 并发：内置锁 Synchronized](https://blog.csdn.net/justloveyou_/article/details/54381099)

## Lock 

如果一段代码被synchronized修饰，当一个线程获取了对应的锁，并且开始执行其他线程便只能一直等待到占有锁的线程释放锁，释放锁一般有三种情况
* 占有锁的线程执行完了代码
* 占有锁的线程发生了异常
* 占有锁的线程进入WAITING释放锁，比如调用wait方法

### 为了解决以下情况出现了Lock

* 在使用synchronized的情况下，假如占有锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞，但是没有释放锁，那么其他线程只能一直等待，没有其他办法，有没有一种机制可以不让线程无限制的等待，比如等待一段时间就返回（解决方案：tryLock(long time, TimeUnit unit)），比如中断等待(解决方案：lockInterruptibly())）这种都可以用Lock解决

* 当多个线程同时读文件是不会发生冲突的，但是如果使用synchronized，多个线程只能一个一个的读文件，那么需要一种机制只要多个线程同时读文件，线程之间可以同时读，Lock也可以解决这种情况 (解决方案：ReentrantReadWriteLock) 。

* 可以通过Lock得知线程是否成功获得锁，而synchronized不行

Lock实现比synchronized关键字更灵活，更广泛，粒度更细，但是需要注意一下几点

* synchronized是java关键字，是Java的内置特性，是基于JVM实现的，其经过编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 两个字节码指令，Lock是一个Java接口，是基于JDK层面实现的，这个接口可以和实现同步访问

* synchronized不需要用户手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用，Lock必须用户手动释放锁（发生异常也不会自动释放锁），如果没有主动释放锁，就可能会导致死锁，因此使用Lock时需要在finally块中释放锁

* Lock 可以让等待锁的线程响应中断，而使用synchronized时，等待的线程会一直等待下去，不能够响应中断；

* 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到；

* Lock可以提高多个线程进行读操作的效率。

在性能上来说，如果竞争资源不激烈，两者的性能是差不多的。而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。

## 锁的概念介绍

### 可重入锁

如果锁具备可重入性，则称作为 可重入锁 。像 synchronized 和 ReentrantLock 都是可重入锁，可重入性实际上表明了 锁的分配粒度：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。

### 可中断锁
顾名思义，可中断锁就是可以响应中断的锁。在Java中，synchronized就不是可中断锁，而Lock是可中断锁。

### 公平锁
公平锁即 尽量 以请求锁的顺序来获取锁。比如，同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。而非公平锁则无法保证锁的获取是按照请求锁的顺序进行的，这样就可能导致某个或者一些线程永远获取不到锁。

在Java中，synchronized就是非公平锁（抢占锁），它无法保证等待的线程获取锁的顺序。而对于ReentrantLock 和 ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为 公平锁（协同式线程调度）。

### 读写锁
读写锁将对临界资源的访问分成了两个锁，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。可以通过readLock()获取读锁，通过writeLock()获取写锁。

### 乐观锁
顾名思义在操作时很乐观，认为操作不会产生并发问题，因此不会上锁，但是在更新时会判断其他线程在这之前有没有对数据进行更改，一般会使用版本号机制或CAS(compare and swap)算法实现。

### 悲观锁
总是假设最坏的情况，每次取数据都会认为其他线程会更改，所以都会加锁，一旦加锁不同线程同时执行时，只能有一个线程执行，其他线程阻塞，直到锁释放

## volatile

由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题：由于 CPU 执行速度很快，而从内存读取数据和向内存写入数据的过程跟 CPU 执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此，在 CPU 里面就有了 高速缓存（寄存器）

也就是说，在程序运行过程中，会将运算需要的数据从主存复制一份到 CPU 的高速缓存当中，那么， CPU 进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：

```java
i = i + 1;
```
　　当线程执行这个语句时，会先从主存当中读取 i 的值，然后复制一份到高速缓存当中，然后CPU执行指令对 i 进行加1操作，然后将数据写入高速缓存，最后将高速缓存中 i 最新的值刷新到主存当中。

这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核 CPU 中，每个线程可能运行于不同的 CPU 中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。

比如，同时有两个线程执行这段代码，假如初始时 i 的值为 0，那么我们希望两个线程执行完之后 i 的值变为 2。但是事实会是这样吗？

可能存在下面一种情况：初始时，两个线程分别读取 i 的值存入各自所在的 CPU 的高速缓存当中，然后线程1 进行加 1 操作，然后把 i 的最新值 1 写入到内存。此时线程 2 的高速缓存当中 i 的值还是 0，进行加 1 操作之后，i 的值为 1，然后线程 2 把 i 的值写入内存。

最终结果 i 的值是 1，而不是 2 。这就是著名的 缓存一致性问题 。通常称这种被多个线程访问的变量为 共享变量 。

`volatile`它核心的思想是： 当 CPU 写数据时，如果发现操作的变量是共享变量，即在其他 CPU 中也存在该变量的副本，会发出信号通知其他 CPU 将该变量的缓存行置为无效状态。因此，当其他 CPU 需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

### 并发编程三个概念

* 原子性

    即一个操作或多个操作，要么全部执行并且还行过程中不会被其他因素打断，要么就不执行

* 可见性

    是指当多个线程访问同一个共享变量时，一个线程修改了这个值，其他线程可以立即看到这个值

* 有序性

    即程序执行的顺序按照代码的先后顺序执行

    *  指令重排序（Instruction Reorder）

        处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的（单线程情形下）。

        指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。也就是说，要想使并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确

### Java的内存模型

Java内存模型，规定所有的变量都是存在主内存中的（类似于之前说的屋里内存），每个线程都有自己的工作内存（类似之前的高速内存），线程对变量的所有操作，都必须在工作内存中进行，不能直接操作主内存，并且每个线程不能其他线程的工作内存

Java语音本身对原子性，可见性，有序性提供了那些保证

* 原子性

    在Java中对基本数据类型的变量`读取和赋值`都是原子性操作,这些操作都是不可中断的，要不执行完成，要么不执行
    ```java
    x = 10;         //语句1
    y = x;         //语句2
    x++;           //语句3
    x = x + 1;     //语句4
    ```
    上看语句只有语句1是原子性操作，其他三个语句不是原子性操作

    Java内存模型只保证了基本的读取和赋值是原子性操作，如果要大范围实行原子性，需要synchronized 和 Lock 来实现

* 可见性

    Java提供了volatile关键字来保证可见性

    当一个共享变量被volatile修饰时，他会保证被修改的值立即更新到主内存，当有其他线程需要读取时，他会去内存中读取新值

    通过synchronized 和 Lock 也能够保证可见性，synchronized 和 Lock 能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会把变量刷新到主内存中，因此可以保证可见性

* 有序性

    Java中可以通过volatile来保证有序性（禁止指令重排），synchronized 和 Lock 不能保证有序性

### 小结

关键字volatile与内存模型紧密相关，是线程同步的轻量级实现，其性能比synchronized要好，在作用对象和范围上，volatile用于修饰变量，synchronized用来就是方法和代码块

volatile保证 可见性和有序性

synchronized保证 原子性和可见性

参考文章：
[Java 并发：volatile 关键字解析
](https://blog.csdn.net/justloveyou_/article/details/53672005)



## 什么是死锁(Deadlock)

死锁是指俩个以上线程永远阻塞的情况，这种情况产生至少需要俩个线程和俩个以上的资源


## 线程池

###  ThreadPoolExecutor
这个是ThreadPoolExecutor的构造，分析一下

```
  public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             threadFactory, defaultHandler);
    }
```

**corePoolSize ：**
线程池核心线程数，默认情况下，核心线程会在线程池一直存活，即使他们处于闲置状态，如果将ThreadPoolExecutor的allowCoreThreadTimeOut设为true。那么闲置的可信线程等待新任务到来时回事超时策略，这个时间由KeepAliveTime所指定，当等待时间超过KeepAliveTime时长时候，和细心线程就会终止

**maximumPoolSize：**
线程池的最大线程数，表示这个线程吃池最多可以创建多少个线程

**KeepAliveTime**
非核心线程闲置超时时长，超过这个时间，非核心线程就会被回收

**unit**
用于指定KeepAliveTime 参数的时间单位，这是一个枚举常有的（TimeUtils。SECONDS 秒）

```
TimeUnit.DAYS;               //天
TimeUnit.HOURS;             //小时
TimeUnit.MINUTES;           //分钟
TimeUnit.SECONDS;           //秒
TimeUnit.MILLISECONDS;      //毫秒
TimeUnit.MICROSECONDS;      //微妙
TimeUnit.NANOSECONDS;       //纳秒
```

**workQueue**
一个阻塞队列，用来储存等待执行的任务，这个参数也很重要，会对线程池产生巨大影响，一般来说，阻塞队列有以下几种选择

```
workQueue的类型为BlockingQueue<Runnable>，通常可以取下面三种类型：

　　1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小；

　　2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；

　　3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务
```

**ThreadFactory**
线程工厂，为线程池提供创建新线程的功能

**defaultHandler**
表示拒绝处理任务时的策略，有下面就几种取值

```
ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 
ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 
ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 
```

ThreadPoolExector执行任务大致遵循以下规则
* （1）如果线程池中线程数量未达到核心线程数，那么会直接启动一个核心线程来执行任务
* （2）如果线程池中线程数量已经超过核心线程的数量那么任务会插入到任务列表中排队等待执行
* （3）如果在步骤二中无法插入，往往是由于任务队列已满，这个时候如果线程数量达到未达到线程池规定的最大值，那么会直接启动一个非核心线程来执行任务
* （4）如果步骤三线程数量以及几个达到线程池规定的最大值，那么就拒绝执行此任务，会调用   ThreadPoolExecutor的RejectedExecutionHandler方法通知调用者

**参数配置**

ThreadPoolExtecutor参数配置，在AscyncTask中有明显的体现，

```
//核心线程最大为4最小为2
 private static final int CORE_POOL_SIZE = Math.max(2, Math.min(CPU_COUNT - 1, 4));
 //线程池最大线程数cup的2倍加1
 private static final int MAXIMUM_POOL_SIZE = CPU_COUNT * 2 + 1;
 //超时时间30s
 private static final int KEEP_ALIVE_SECONDS = 30;
 //任务队列容量128
   private static final BlockingQueue<Runnable> sPoolWorkQueue =
            new LinkedBlockingQueue<Runnable>(128);
```

### 线程池的分类
并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池：

**FixedThreadPool**

通过 Executors的newFixedThreadPool方法来创建，他是一个线程数固定的线程池，当线程处于空下线状态时，他们并不会被回收，除非线程池被关闭，当所有的线程处于活动状态时，新任务都会处于等待状态，知道有线程空闲出来，由于FixedThreadPool只有核心线程数并且这些不会被回收，这就意味他能更加快速的响应外界请求

```
//只有核心线程，没有超时机制，任务队列，没有大小限制
    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }

```
**CachedThreadPool**

通过Executors的newCachedThreadPool来创建，他是一种线程数量不定的线程池，他只有非核心线程，其中最大线程数为  Integer.MAX_VALUE，由于这个是一个很大的数字，时间就相当于最大线程数任意大，当线程池中的线程都处于活动中，线程池会创建新的线程来处理任务，否则就用空闲线程处理任务，线程池中的空闲线程都有超时机制，这个超时是60s超过60s限制线程被回收，和FixedThreadPool不同的是，CachedThreadPool的任务队列是个空集合
这将导致任何任务都会立即执行，因为这种状态下无法进行插入任务，这种线程池适合处理大量耗时较少的任务，当整个线程池处于闲置时，线程都会由于超时而终止，这时候几乎不占用任何资源

```
//没有核心线程，只有非很线程数量无限多
   public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
```

 **ScheduledThreadPool**

通过Executors的newScheduledThreadPool来创建，他的核心线程数是固定的，而费和细心线程数是没哟限制的，并且当非核心线程闲置会立刻被回收，这类线程池主要用于执行定时任务和固定周期的重复任务

```
    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE,
              DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
              new DelayedWorkQueue());
    }

```

**SingleThreadExecutor**

通过Executors的newSingleThreadExecutor来创建
这类线程池只有一个核心线程，他确保所有的任务都在同一个线程中顺序执行，他的意义在于同意外界所有任务到一个线程中，这使得这些任务之间不需要处理线程同步问题

```
  public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
```
### 线程池的线程复用：
这里就需要深入到源码addWorker()：它是创建新线程的关键，也是线程复用的关键入口。最终会执行到runWoker，它取任务有两个方式：

firstTask：这是指定的第一个runnable可执行任务，它会在Woker这个工作线程中运行执行任务run。并且置空表示这个任务已经被执行。
getTask()：这首先是一个死循环过程，工作线程循环直到能够取出Runnable对象或超时返回，这里的取的目标就是任务队列workQueue，对应刚才入队的操作，有入有出。

其实就是任务在并不只执行创建时指定的firstTask第一任务，还会从任务队列的中通过getTask()方法自己主动去取任务执行，而且是有/无时间限定的阻塞等待，保证线程的存活。

## 为什么wait(), notify()和notifyAll()必须在同步方法或者同步块中被调用？

　　wait/notify机制是依赖于Java中Synchronized同步机制的，其目的在于确保等待线程从Wait()返回时能够感知通知线程对共享变量所作出的修改。如果不在同步范围内使用，就会抛出java.lang.IllegalMonitorStateException的异常。

## 线程池调优

* 设置最大线程数，防止线程资源耗尽；

* 使用有界队列，从而增加系统的稳定性和预警能力(饱和策略)；

* 根据任务的性质设置线程池大小：CPU密集型任务(CPU个数个线程)，IO密集型任务(CPU个数两倍的线程)，混合型任务(拆分)。

## 为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object类里？
```
Object lock = new Object();
synchronized (lock) {
    lock.wait();
    ...
}
```

　　Wait-notify机制是在获取对象锁的前提下不同线程间的通信机制。在Java中，任意对象都可以当作锁来使用，由于锁对象的任意性，所以这些通信方法需要被定义在Object类里。

### 有界队列
* 1.初始的poolSize < corePoolSize，提交的runnable任务，会直接做为new一个Thread的参数，立马执行 。
* 2.当提交的任务数超过了corePoolSize，会将当前的runable提交到一个block queue中。
* 3.有界队列满了之后，如果poolSize < maximumPoolsize时，会尝试new 一个Thread的进行救急处理，立马执行对应的runnable任务。
* 4.如果3中也无法处理了，就会走到第四步执行reject操作。
### 无界队列
* 与有界队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。
* 当有新的任务到来，系统的线程数小于corePoolSize时，则新建线程执行任务。当达到corePoolSize后，就不会继续增加，若后续仍有新的任务加入，而没有空闲的线程资源，则任务直接进入队列等待。若任务创建和处理的速度差异很大，无界队列会保持快速增长，直到耗尽系统内存。
* 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略。

# 其他

## String 为什么要设计成不可变的？
String是不可变的（修改String时，不会在原有的内存地址修改，而是重新指向一个新对象），String用final修饰，不可继承，String本质上是个final的char[]数组，所以char[]数组的内存地址不会被修改，而且String 也没有对外暴露修改char[]数组的方法。不可变性可以保证线程安全以及字符串串常量池的实现。

## String，StringBuffer，StringBuilder有哪些不同？
三者在执行速度方面的比较：StringBuilder >  StringBuffer  >  String
String每次变化一个值就会开辟一个新的内存空间
StringBuilder：线程非安全的
StringBuffer：线程安全的


## equals 和 hashcode 的关系？
hashcode和equals的约定关系如下：

* 原则 1 ： 如果 x.equals(y) 返回 “true”，那么 x 和 y 的 hashCode() 必须相等 ；
* 原则 2 ： 如果 x.equals(y) 返回 “false”，那么 x 和 y 的 hashCode() 有可能相等，也有可能不等 ；
* 原则 3 ： 如果 x 和 y 的 hashCode() 不相等，那么 x.equals(y) 一定返回 “false” ；


## 为什么复写equals方法的同时需要复写hashcode方法，前者相同后者是否相同，反过来呢？为什么？
要考虑到类似HashMap、HashTable、HashSet的这种散列的数据类型的运用，当我们重写equals时，是为了用自身的方式去判断两个自定义对象是否相等，然而如果此时刚好需要我们用自定义的对象去充当hashmap的键值使用时，就会出现我们认为的同一对象，却因为hash值不同而导致hashmap中存了两个对象，从而才需要进行hashcode方法的覆盖。

## java中==和equals？

### ==
* 若操作数的类型是基本数据类型，则该关系操作符判断的是左右两边操作数的值是否相等
* 若操作数的类型是引用数据类型，则该关系操作符判断的是左右两边操作数的内存地址是否相同。也就是说，若此时返回true,则该操作符作用的一定是同一个对象。

### equals

其本意 是 比较两个对象的 content 是否相同

必要的时候，我们需要重写该方法，避免违背本意，且要遵循上述原则

### java 加载顺序
现在new一个Dog的对象假如没有继承

* 首次创建Dog对象或者访问Dog的静态成员方法时，载入Dog.class
* 初始化静态变量和静态代码块
* new Dog时，在堆上分配足够的空间
* 初始化成员变量，代码块
* 调用构造器

如果有继承

* 先加载父类的class,初始化父类的静态变量
* 在加载子类的class，初始化子类的静态变量
* 先new父类对象，再new子类对象


# Java继承

[Java继承](https://blog.csdn.net/qq_34760508/article/details/84763916)

# JVM
java虚拟机在执行的过程中，会把他的内存划分为一下几部分
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210512101840130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NzYwNTA4,size_16,color_FFFFFF,t_70)
**程序计数器**

程序计数器是一个较小的内存空间，他可以看做是当前线程所执行字节码的行号指示器，由于java的多线程是通过线程轮流切换并分配处理器执行时间来实现的，任何一个确定时刻，一个处理器（对应于多核中的一个内核）都只会执行一个线程中的指令，因此为了每个线程切换后回到正确的位置，每个线程都有一个独立的程序计数器，各线程之间程序计数器互不影响，我们称为线程私有内存，是一个唯一没有内存溢出的区域

**Java虚拟机栈**

Java虚拟机栈也是线程私有的，他描述的的是Java方法执行的内存模型，每个方法执行的同时都要创建一个栈帧，用于储存局部变量表，操作数栈，动态链接，方法出口等信息，每个方法从调用到执行完成，都对应一个栈帧从虚拟机从入栈到出栈的过程

**本地方法栈**

一般认为他和虚拟机栈是一体的

**Java堆**

java堆是虚拟机占用内存最大的一块，他是线程共享的一块内存，在虚拟机启动时创建，此区域唯一的目的就是防止对象的实例，几乎所有的对象实例都是在这里分配内存，java堆是垃圾回收的主要区域，处于屋里内存不连续的空间

**方法区**

和Java堆一样，是各个线程共享的区域，它用于储存已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码

**运行时常量池**

是方法去的一部分，class文件除了有类的版本，字段，方法，接口等描述信息，还有一项信息是常量池，用于存放编译器生成的各种字面量和符号引用

## 栈和堆

局部变量的基本数据类型和引用都储存在栈中，引用对象的实体储存在堆中，因为他们属于方法的变量，生命周期岁方法的结束而结束

成员变量全部储存在堆中（包括基本数据类型，引用和引用的实体），因为他们属于类，类最终还是要被new出来的

## 哪里回收垃圾

其中线程的私有的程序计数器，虚拟机栈，本地方法栈，这三个区域随线程而生，随线程而死，这个几个区域的内存分配和回收，都具有确定性，这几个区域不用过多的考虑回收，因为线程结束或者方法结束，内存自然就回收了

而java的堆和方法去不一样，一个接口多个实现类需要的内存可能不一样，在程序的运行期间才知道需要创建那些对象，这些内存的分配和回收都是动态的，垃圾回收主要关注这部分

## 如何知道对象是否可回收

* 引用计数法
    给对象加一个引用计数器，有地方引用的时候就加一，引用失效就减一，在任何时刻计数为0就是没有被引用的，但是很难解决对象相互引用的情况，java虚拟机没有使用这种方法

* 可达算法
    现在主流的实现都是使用可达算法，来判断对象是否存活，这个算法的基本思路就是通过GcRoot作为起点，从这些起点向下搜索，搜索过的路径叫做引用连， 当一个对象到GCRoot没有任何引用链时，说明此对象不可用

### 可以作为GcRoot的对象包括以下几种

* 虚拟栈中引用的对象
* 方法区静态属性引用的对象
* 方法区常量引用的对象
* 本地方法栈中jni引用的对象

## 引用的分类

* 强引用（StrongReference）

    强引用是指在代码中普遍存在的Object obj =new Object（），这类的引用有引用变量指向时，永远不会被垃圾回收，JVM宁可抛出OutofMemory也不会回收这种对象，如果想中断某个强引用和对象的之间的联系，可以将引用赋值为null
* 软引用（SoftReference）

    用来描述一些有用但非必须的对象，对于软引用关联着的对象，在系统发生内存溢出之前，会把这些对象列入回收范围之内，进行二次回收，如果这次回收还没有足够内存，才会抛出内存溢出异常，软引用经常用于内存敏感的高速缓存，比如，网页缓存，图片缓存，防止内存泄漏，增强代码的健壮性

    ```java
    // 强引用
    String strongReference = new String("abc");
    // 软引用
    String str = new String("abc");
    SoftReference<String> softReference = new SoftReference<String>(str);
    ```
* 弱引用（WeakReference）

    表示非必须的对象，不管内存是否充足，都会回收该对象
    只要JVM进行垃圾回收，被弱引用关联的对象必定会被回收掉。不过要注意的是，这里所说的被弱引用关联的对象是指只有弱引用与之关联，如果存在强引用同时与之关联，则进行垃圾回收时也不会回收该对象（软引用也是如此）。
    ```java
    String str = new String("abc");
    WeakReference<String> weakReference = new WeakReference<>(str);
    // 弱引用转强引用
    String strongReference = weakReference.get();
    ```

* 虚引用（PhontomReference）

    虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。

## finalize
即使在可达性算法中，不可达对象，也不是非死不可，这时他们处于“缓刑”阶段，要宣告一个对象真正死亡需要至少俩个标记阶段， 如果发现对象没有引用链，则会进行第一次标记，并进行一次筛选，筛选的条件是此对象是否有必要进行finalize（）方法，当对象没有覆盖finalize(),或者finalize（）已经调用过，这俩种都视为“没有必要执行”
若果这个对象被视为 有必要执行，则会放入到一个F-Queue队列 中，并稍后有虚拟机建立一个低优先级的Finalizer线程去执行它，所谓的执行，是指会触发这个方法，但并不承诺等他执行完成，并不建议大家用这个方法做回收，try-finally 更加靠谱

## 回收方法区

### 主要回收两类

* 废弃常量

    假如一个abd字符串 已经进入常量池，而当前程序没有任何一个 string 叫做adc ，也没有其他地方引用这个常量，就是废弃常量
无用的类

* 判断一个无用的类条件更加的苛刻
    * 所有类的实例都被回收，也就是java堆中不存在该类的任何实例
    * 加载该类的classloader 被回收
    * 该类对应的java.lang.class 对象没有任何地方被引用，无法在任何地方通过反 射，访问该类的方法
    * 满足上面那三个条件，就可以被回收


## 垃圾回收算法

* 标记-清除算法

    该算法分为标记和清除俩个阶段，首先需要标记出需要回收的各个对象，在标记完成后统一回收标记对象，他有俩个不足

    1 效率问题：标记和清除俩个过程效率都不是很高

    2 空间问题：会产生大量不连续的空间

* 复制算法

    为了解决效率问题，可以把内存分为安全相同的俩块，每次只是用其中的一块，这块用完了就把还存活的复制到另一块上，然后把使用过的空间一次性清理掉，不足就是会把内存缩小为原来的一半
* 标记整理算法

    复制算法在存活较多的情况下，效率较低，而且会浪费一半的空间，所以老年代不能选择这种算法，根据老年代存活率很高的特点，又提出一种标记整理法，标记过程和”标记清除“一样，但后续步骤不是对可回收对象进行清理，而是让所有存活的对象，想一端移动，然后直接清理端以外的内存

* 分代收集算法
当前虚拟机大部分采用，分代收集算法，这种算法并没有特别思想，只是根据对象的存活周期不同把内存划分为几块，一般是吧java堆分为新生代和老年代，这样就可以根据年代的特点采用不同的算法，提高效率，新生代每次垃圾回收都会有大量的对象死去，少量存活，那就用复制算法，老年代存活率较低，那就使用标记-清除，或标记-整理法

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190821141912419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NzYwNTA4,size_16,color_FFFFFF,t_70)
* 新生代（Young Generation）
大多数对象在新生代中创建，其中很多对象的生命周期很短，每次新生代的垃圾回收（又称 Minor GC），只有少量对象存活，所以选择复制算法，因为少量的复制成本就可以完成
新生代又分为三个区，一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成，当Eden区满了之后，还存活的对象复制到Survivor区中的一个，当这个Survivor区满了之后，此区存活但不满足晋升条件的对象，复制到另一个Survivor区，对象每一次Minor GC年龄加一，达到年龄的阈值后，晋升老年区，默认的阈值为15岁

* 老年代（Old Generation）
新生代经历n次垃圾回收，还存活的对象就会被放到老年代，此区域中对象存活率高，老年代的垃圾回收，通常用标记清理和标记整理的方法，整堆包括新生代和老年代的垃圾回收称为Full GC

* 永久代（Perm Generation）
主要存放元数据，如Class何Method的元数据，与垃圾回收对象的关系不大，相对于新生代和老年代来说，该区划分对垃圾回收影响较小



## 什么时候回收
**GC的类型：**

* 分配内存不够引起的GC，会stop world，是并发GC，其他线程都会停止，直到GC完成
   * 当你new一个新的对象时，如果内存不够会进行**Full GC**
* 内存达到一定的阈值，进行的GC，是一个后台GC，不会stop world
  * 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。
   * Minor GC触发条件：当Eden区满时，触发Minor GC。
    * 老年代 GC（Full GC ）：指发生在老年代的 GC，经常会伴随至少一次的 Minor GC 。MajorGC 的速度一般会比 Minor GC 慢 10倍以上。

    * Full GC触发条件：（1）老年代空间不足（2）升到老年代的对象大于老年代剩余空间

* 显示调用时进行的GC，显式调用System.gc时会调用Full GC


# JVM 类加载机制
## 概述

`Java`文件最终会被编译成`Class`文件，`Class`文件最终需要加载到`JVM`中才能运行和使用，虚拟机把描述类的`Class`文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被直接使用的`Java`类型，这就是虚拟机的类加载机制

在java的语言里，类的`加载，链接，初始化`，都是在运行期间进行的，这样虽然会增加一些性能开销，但是会让`Java`程序更加的灵活，`Java`天生可以动态扩展语言的特性就是依赖运行期动态加载和动态链接来实现的

## 类的加载过程


类被加载到虚拟机内存开始，到卸载出内存为止，他的整个生命周期包括，`加载，验证，准备，解析，初始化，使用，和卸载`七个阶段，其中`验证，准备，解析`3个部分统称为`连接`

![](https://img-blog.csdnimg.cn/img_convert/51017f9d87d4fd5c1782565e86b6e343.png)

下面我们全面了解一下类加载的加载和初始化，链接主要是确保安全性

### 加载

`加载`是`类加载`的一个阶段，不要混淆这俩个概念

加载阶段主要完成了下面三个事情

* 通过一个类的全限定名获取定义此类的二进制字节流
* 将这个字节流所代表的静态存储结构转化为方法区运行时数据结构
* 在内存中生成一个java.lang.class对象，作为方法区这个类的各个数据的访问入口

这三个定义不算具体，第一个`通过一个类的全限定名获取定义此类的二进制字节流`,没有指定从哪里获取，怎样获取，这样就给了开发人员很大的灵活性，比如
* 我们可以从ZIP中获取，比如jar
* 我们可以从网络中获取
* 运行时计算生成，这种场景运用最多的是动态代理技术
* ...

加载阶段完成后，虚拟机外部的二进制字节流，就按照虚拟机所需的格式存入到了方法区之中，然后实例化一个java.lang.class对象，虽然他是对象，但是他存在方法区里面


### 初始化

初始化是类加载的最后一步，前面的类加载过程中，除了加载阶段用户可以控制以外，其余动作都由虚拟机主导，到了初始化阶段，才是真正执行类中定义的java程序代码

**关于类加载的初始化阶段，在虚拟机规范严格规定了有且只有5种场景必须对类进行初始化：**

* 使用new关键字实例化对象时，读取或者设置一个静态字段（不包括编译期常量），以及调用静态方法的时候，必须触发类加载的初始化过程（类加载的最终阶段）
* 使用反射对类进行调用的时候，如果类还没初始化，那么就要初始化
* 当初始化一个类的时候，如果其父类还没初始化，那么则先触发父类的初始化
* 当java虚拟机启动时，用户需要制定一个要执行的主类（包含main方法的类），虚拟机会先初始化这个主类
* 当使用JDK 1.7 的动态语言支持时，如果一个`java.lang.invoke.MethodHandle `实例最后解析结果为`REF_getStatic、REF_putStatic、REF_invokeStatic`的方法句柄，并且这个方法句柄对应类没有初始化时，必须触发其初始化(这点看不懂就算了，这是1.7的新增的动态语言支持，其关键特征是它的类型检查的主体过程是在运行期而不是编译期进行的，这是一个比较大点的话题，这里暂且打住)

## 类与类加载器

虚拟机把类加载阶段的`通过一个类的全限定名获取定义此类的二进制字节流`,这个动作放到java虚拟机外部去实现，以便让用户来决定如何去获取需要的类。实现这个动作的代码块叫做`类加载器`

类加载器虽然最用于类的加载阶段，但是他在java程序起到的作用不限类的加载阶段，比如，如何判断俩个类`相等`,只有俩个类是被同一个加载器加载的前提下才有意义，否则即使俩个类源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，俩个类必定不相等

这里说的相等，包括类的`Class`对象`equals方法`，也包括`Instance of` 关键字判断

    
## 双亲委派模型

**双亲委派模型的工作过程**

如果一个加载器收到了类加载的请求，他首先不会自己尝试加载这个类，而是把这个请求委派给父类加载器完成，每一个层次的加载器都是如此，因此所有的加载请求，都应该传入到顶层的启动加载器中，只有父类加载器反馈，无法完成这个加载请求，自加载器才会尝试自己去加载

**双亲委托模型的好处**
* 避免重复加载，如果已经加载，就不需要再次加载
* 安全，如果你定义`String`类来代替系统的`String`类，这样会导致风险，但是在双亲委托模型中，`String`类在`java`虚拟机启动时就被加载了，你自定义的`String`类是不会被加载的



























































